{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install librosa\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import zipfile\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from torch.utils.data import DataLoader\n",
    "from Misc import Misc\n",
    "from CustomDataset import CustomDataset\n",
    "from EuclideanDistanceLoss import EuclideanDistanceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../data/LivingRoom_preprocessed_hack\"\n",
    "# Dimensions of the living room\n",
    "X_MIN = -4000\n",
    "X_MAX = 500\n",
    "Y_MIN = -4000\n",
    "Y_MAX = 2000\n",
    "MISC = Misc(start_time=0, end_time=50000, sr=44100, target_sr=16000)\n",
    "EUCLIDEAN_LOSS = EuclideanDistanceLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_h1 = np.load(DATASET_PATH + \"/Human1/centroid.npy\")\n",
    "centroids_h2 = np.load(DATASET_PATH + \"/Human2/centroid.npy\")\n",
    "deconvoled_trim_h1 = np.load(DATASET_PATH + \"/Human1/deconvoled_trim.npy\")\n",
    "deconvoled_trim_h2 = np.load(DATASET_PATH + \"/Human2/deconvoled_trim.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deconvoled Trim Human 1 Shape: \", deconvoled_trim_h1.shape)\n",
    "print(\"Deconvoled Trim Human 2 Shape: \", deconvoled_trim_h2.shape)\n",
    "print(\"Centroids Huma 1 Shape: \", centroids_h1.shape)\n",
    "print(\"Centroids Human 2 Shape: \", centroids_h2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data_mfcc_h1, preprocessed_data_rms_h1, preprocessed_data_zcr_h1 = MISC.preprocess_knn(deconvoled_trim=deconvoled_trim_h1)\n",
    "preprocessed_data_mfcc_h2, preprocessed_data_rms_h2, preprocessed_data_zcr_h2 = MISC.preprocess_knn(deconvoled_trim=deconvoled_trim_h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessed RMS Human 1 data: \", preprocessed_data_rms_h1.shape)\n",
    "print(\"Preprocessed Zero-Crossing Rate Human 1 data: \", preprocessed_data_zcr_h1.shape)\n",
    "print(\"Preprocessed MFCC Human 1 data: \", preprocessed_data_mfcc_h1.shape)\n",
    "print(\"Preprocessed RMS Human 2 data: \", preprocessed_data_rms_h2.shape)\n",
    "print(\"Preprocessed Zero-Crossing Rate Human 2 data: \", preprocessed_data_zcr_h2.shape)\n",
    "print(\"Preprocessed MFCC Human 2 data: \", preprocessed_data_mfcc_h2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot audio features for each instance and channel\n",
    "for instance_index in range(preprocessed_data_mfcc_h2.shape[0]):\n",
    "    for channel_index in range(preprocessed_data_mfcc_h2.shape[1]):\n",
    "        mfcc_features = preprocessed_data_mfcc_h2[instance_index, channel_index]\n",
    "        MISC.plot_audio_features(instance_index=instance_index, chan_index=channel_index, mfcc=mfcc_features)\n",
    "    break\n",
    "\n",
    "# Plot audio features for each instance and channel\n",
    "for instance_index in range(preprocessed_data_zcr_h2.shape[0]):\n",
    "    for channel_index in range(preprocessed_data_zcr_h2.shape[1]):\n",
    "        zero_crossing_rate = preprocessed_data_zcr_h2[instance_index, channel_index] \n",
    "        MISC.plot_audio_features(instance_index=instance_index, chan_index=channel_index, zcr=zero_crossing_rate)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_h1 = CustomDataset(preprocessed_data_rms=preprocessed_data_rms_h1, coordinates=centroids_h1)\n",
    "dataset_h2 = CustomDataset(preprocessed_data_rms=preprocessed_data_rms_h2, coordinates=centroids_h2)\n",
    "\n",
    "# Access a sample from the dataset\n",
    "features_list, coordinates = dataset_h1[1]\n",
    "print(\"Features List Length:\", len(features_list))\n",
    "print(\"Features Shape (Microphone 1):\", features_list[0])\n",
    "print(\"Features Shape (Microphone 2):\", features_list[1])\n",
    "print(\"Features Shape (Microphone 3):\", features_list[2])\n",
    "print(\"Features Shape (Microphone 4):\", features_list[3])\n",
    "print(\"Coordinates:\", coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = EUCLIDEAN_LOSS\n",
    "\n",
    "def custom_scoring(self, estimator, X, y):\n",
    "        pred_coords = estimator.predict(X)\n",
    "        ed = np.mean([criterion(torch.tensor(p), torch.tensor(t)) for p, t in zip(pred_coords, y)])\n",
    "        return -ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': np.arange(1, 40)}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, scoring=custom_scoring)\n",
    "\n",
    "grid_search.fit(dataset_h1.preprocessed_data_rms, dataset_h1.coordinates)\n",
    "\n",
    "print(\"GridSearchCV Best Parameters:\", grid_search.best_params_['n_neighbors'])\n",
    "print(\"GridSearchCV Best Scoring:\", -grid_search.best_score_)  # Negate for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor(n_neighbors=grid_search.best_params_['n_neighbors'])\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(dataset_h1.preprocessed_data_rms, dataset_h1.coordinates)\n",
    "\n",
    "predicted_coordinates = knn_model.predict(dataset_h2.preprocessed_data_rms)\n",
    "\n",
    "mse = mean_squared_error(centroids_h2, predicted_coordinates)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "mae = mean_absolute_error(centroids_h2, predicted_coordinates)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "# Calculate localization errors for each prediction\n",
    "errors = []\n",
    "for pred_coords, true_coords in zip(predicted_coordinates, dataset_h2.coordinates):\n",
    "    error = criterion(torch.tensor(pred_coords), torch.tensor(true_coords))\n",
    "    errors.append(error)\n",
    "\n",
    "errors = np.array(errors)\n",
    "mean_error = np.mean(errors)\n",
    "stdev_error = np.std(errors)\n",
    "\n",
    "print(\"Localization Error: {:.2f} ({:.2f})\".format(mean_error, stdev_error))\n",
    "print(\"Score: \", knn_model.score(dataset_h2.preprocessed_data_rms, dataset_h2.coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all true and predicted coordinates from all data points\n",
    "all_true_coords = dataset_h2.coordinates.reshape(-1, 2)\n",
    "all_pred_coords = predicted_coordinates.reshape(-1, 2)\n",
    "\n",
    "# Plot all true and predicted coordinates on a single graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(all_true_coords[:, 0], all_true_coords[:, 1], color='blue', label='True Coordinates')\n",
    "#plt.scatter(all_pred_coords[:, 0], all_pred_coords[:, 1], color='red', label='Predicted Coordinates')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('True vs Predicted Coordinates')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all true and predicted coordinates from all data points\n",
    "all_true_coords = dataset_h2.coordinates.reshape(-1, 2)\n",
    "all_pred_coords = predicted_coordinates.reshape(-1, 2)\n",
    "\n",
    "# Plot all true and predicted coordinates on a single graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "#plt.scatter(all_true_coords[:, 0], all_true_coords[:, 1], color='blue', label='True Coordinates')\n",
    "plt.scatter(all_pred_coords[:, 0], all_pred_coords[:, 1], color='red', label='Predicted Coordinates')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('True vs Predicted Coordinates')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Crossing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_h1 = CustomDataset(preprocessed_data_zcr=preprocessed_data_zcr_h1, _type=\"zcr\", coordinates=centroids_h1)\n",
    "dataset_h2 = CustomDataset(preprocessed_data_zcr=preprocessed_data_zcr_h2, _type=\"zcr\", coordinates=centroids_h2)\n",
    "\n",
    "rms_features = np.sqrt(np.mean(dataset_h1.preprocessed_data_zcr**2, axis=-1))\n",
    "X_train = rms_features.reshape(1000, 4)\n",
    "y_train = dataset_h1.coordinates\n",
    "rms_features = np.sqrt(np.mean(dataset_h2.preprocessed_data_zcr**2, axis=-1))\n",
    "X_test = rms_features.reshape(104, 4)\n",
    "y_test = dataset_h2.coordinates\n",
    "\n",
    "param_grid = {'n_neighbors': np.arange(1, 40)}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, scoring=custom_scoring)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors=grid_search.best_params_['n_neighbors'])\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "predicted_coordinates = knn_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predicted_coordinates)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predicted_coordinates)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "# Calculate localization errors for each prediction\n",
    "errors = []\n",
    "for pred_coords, true_coords in zip(predicted_coordinates, dataset_h2.coordinates):\n",
    "    error = criterion(torch.tensor(pred_coords), torch.tensor(true_coords))\n",
    "    errors.append(error)\n",
    "\n",
    "errors = np.array(errors)\n",
    "mean_error = np.mean(errors)\n",
    "stdev_error = np.std(errors)\n",
    "\n",
    "print(\"Localization Error: {:.2f} ({:.2f})\".format(mean_error, stdev_error))\n",
    "print(\"Score: \", knn_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
